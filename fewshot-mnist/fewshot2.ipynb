{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMA92a2Pnke1lpFnwu9C+kP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pxndey/dl-projects-2/blob/main/fewshot-mnist/fewshot2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easyfsl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRs31CHecWzw",
        "outputId": "93d24523-a1b1-4987-9b4d-75e141e83d61"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: easyfsl in /usr/local/lib/python3.10/dist-packages (1.5.0)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from easyfsl) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from easyfsl) (1.5.3)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from easyfsl) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from easyfsl) (0.16.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from easyfsl) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->easyfsl) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->easyfsl) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->easyfsl) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->easyfsl) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->easyfsl) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->easyfsl) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->easyfsl) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->easyfsl) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->easyfsl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->easyfsl) (2023.3.post1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->easyfsl) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->easyfsl) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->easyfsl) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->easyfsl) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->easyfsl) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->easyfsl) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->easyfsl) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.7.0->easyfsl) (2.31.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->easyfsl) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.5.0->easyfsl) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.7.0->easyfsl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.7.0->easyfsl) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.7.0->easyfsl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.7.0->easyfsl) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.5.0->easyfsl) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision.transforms import Resize\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import resnet18\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "Kz-KJuWXVxdz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ProtoNet(nn.Module):\n",
        "    def __init__(self, backbone, output_channels, hidden_size=64):\n",
        "        super(ProtoNet, self).__init__()\n",
        "        self.backbone = backbone\n",
        "        self.fc = nn.Linear(hidden_size * 7 * 7, output_channels)\n",
        "\n",
        "    def forward(self, support_images, support_labels, query_images):\n",
        "        # Extract the features of support and query images\n",
        "        z_support = self.backbone(support_images)\n",
        "        z_query = self.backbone(query_images)\n",
        "\n",
        "        # Infer the number of different classes from the labels of the support set\n",
        "        n_way = len(torch.unique(support_labels))\n",
        "        # Prototype i is the mean of all instances of features corresponding to labels == i\n",
        "        z_proto = torch.cat(\n",
        "            [\n",
        "                z_support[torch.nonzero(support_labels == label)].mean(0)\n",
        "                for label in range(n_way)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Compute the euclidean distance from queries to prototypes\n",
        "        dists = torch.cdist(z_query, z_proto)\n",
        "\n",
        "        # And here is the super complicated operation to transform those distances into classification scores!\n",
        "        scores = -dists\n",
        "        return scores\n",
        "\n",
        "\n",
        "resnet18_one_channel = resnet18(pretrained=False)\n",
        "resnet18_one_channel.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "model = ProtoNet(backbone=resnet18_one_channel, output_channels=10).to(device)"
      ],
      "metadata": {
        "id": "TPaS3Xa8V0SM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "961e09d2-fb25-45c2-ec8f-f10b0e73213e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Hyperparameters\n",
        "num_epochs = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    Resize((224, 224))  # Add this line to resize the images to 224x224\n",
        "])\n",
        "mnist_train = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "mnist_test = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "# DataLoaders for training and testing\n",
        "\n",
        "\n",
        "convolutional_network = torchvision.models.resnet18(pretrained=True)\n",
        "convolutional_network.fc = nn.Flatten()\n",
        "\n",
        "# Instantiate the Prototypical Network\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training and testing loss lists for plotting\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "# Hyperparameter for early stopping\n",
        "early_stop_patience = 10\n",
        "best_test_loss = float('inf')\n",
        "counter = 0\n"
      ],
      "metadata": {
        "id": "EafE1DAJV6lG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c46a024-2d87-457f-c9a6-e73cbc719372"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# for batch in train_loader:\n",
        "#   support,labels = batch\n",
        "#   support, labels = support.to(device), labels.to(device)\n",
        "#   print(labels)\n",
        "#   fig,axs = plt.subplots(2,5)\n",
        "#   for i in range(2):\n",
        "#     for j in range(5):\n",
        "#       image = np.squeeze(support[i*5+j].cpu().numpy(), axis=0)\n",
        "#       axs[i,j].imshow(image)\n",
        "    # plt.imshow(image, cmap='gray')  # Assuming it's a grayscale image\n",
        "\n",
        "#   break\n"
      ],
      "metadata": {
        "id": "ZQK8JjMwVv2k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10  # Number of classes in MNIST\n",
        "num_shots = 5   # Number of shots per class\n",
        "num_query = 1     # Number of query examples per class\n",
        "train_loader = DataLoader(mnist_train, batch_size=num_shots * num_classes, shuffle=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=num_query * num_classes, shuffle=True)\n",
        "\n",
        "for batch in train_loader:\n",
        "    # image = np.squeeze(batch[0][0].numpy(), axis=0)\n",
        "    # print(batch[1][0])\n",
        "    # plt.imshow(image, cmap='gray')  # Assuming it's a grayscale image\n",
        "    # # break\n",
        "    support,labels = batch\n",
        "    support, labels = support.to(device), labels.to(device)\n",
        "    # print(labels.shape)\n",
        "    print(support.shape)\n",
        "    support_images = support[:num_shots * (num_classes - 1)]\n",
        "    print(support_images.shape)\n",
        "    query_images = support[num_shots * (num_classes - 1):]\n",
        "    print(query_images.shape)\n",
        "    support_labels = labels[:num_shots * (num_classes - 1)]\n",
        "    query_labels = labels[num_shots * (num_classes - 1):]\n",
        "    # image = np.squeeze(query_images[0].cpu().numpy(), axis=0)\n",
        "    # plt.imshow(image)\n",
        "    print(support_labels.shape)\n",
        "    print(query_labels.shape)\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hdkkfvz1dDlU",
        "outputId": "55f8d704-7282-42a6-8833-812507069036"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50, 1, 224, 224])\n",
            "torch.Size([45, 1, 224, 224])\n",
            "torch.Size([5, 1, 224, 224])\n",
            "torch.Size([45])\n",
            "torch.Size([5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Training and testing accuracy lists for plotting\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "# Training loop with early stopping and accuracy calculation\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    for batch in train_loader:\n",
        "        images, labels = batch\n",
        "        images, labels =images.to(device), labels.to(device)\n",
        "\n",
        "        # Split the support set into support images and query images\n",
        "        support_images = support[:num_shots * (num_classes - 1)]\n",
        "        # print(support_images.shape)\n",
        "        query_images = support[num_shots * (num_classes - 1):]\n",
        "        # print(query_images.shape)\n",
        "        support_labels = labels[:num_shots * (num_classes - 1)]\n",
        "        query_labels = labels[num_shots * (num_classes - 1):]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Call the modified forward method\n",
        "        outputs = model.forward(support_images, support_labels, query_images)\n",
        "\n",
        "        # Flatten the outputs and labels to match the cross-entropy function requirements\n",
        "        outputs = outputs.view(-1)\n",
        "        labels = labels.view(-1)\n",
        "        labels = labels.to(torch.float32)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        _, predicted_train = torch.max(outputs.data, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted_train == labels).sum().item()\n",
        "\n",
        "    # Calculate average training loss and accuracy\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "    train_accuracy = correct_train / total_train\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Print and plot training loss and accuracy\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Avg. Training Loss: {avg_train_loss:.4f}, Training Accuracy: {train_accuracy * 100:.2f}%')\n",
        "\n",
        "    # Testing loop with early stopping and accuracy calculation\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            query_set, labels = batch\n",
        "            query_set, labels = query_set.to(device), labels.to(device)\n",
        "\n",
        "            # Call the modified forward method\n",
        "            outputs = model.forward(support_images, support_labels, query_images)\n",
        "\n",
        "            # Flatten the outputs and labels to match the cross-entropy function requirements\n",
        "            outputs = outputs.view(-1, num_classes)\n",
        "            labels = labels.view(-1)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # Calculate testing accuracy\n",
        "            _, predicted_test = torch.max(outputs.data, 1)\n",
        "            total_test += labels.size(0)\n",
        "            correct_test += (predicted_test == labels).sum().item()\n",
        "\n",
        "    # Calculate average testing loss and accuracy\n",
        "    avg_test_loss = test_loss / len(test_loader)\n",
        "    test_losses.append(avg_test_loss)\n",
        "    test_accuracy = correct_test / total_test\n",
        "    test_accuracies.append(test_accuracy)\n",
        "\n",
        "    # Print and plot testing loss and accuracy\n",
        "    print(f'Avg. Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy * 100:.2f}%')\n",
        "\n",
        "    # Early stopping check\n",
        "    if avg_test_loss < best_test_loss:\n",
        "        best_test_loss = avg_test_loss\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "        if counter >= early_stop_patience:\n",
        "            print(f'Early stopping at epoch {epoch+1} as test loss has not improved for {early_stop_patience} consecutive epochs.')\n",
        "            break\n",
        "\n",
        "# ... (rest of the code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "OfhFZwKEV_wQ",
        "outputId": "d8032e4b-6d4e-473e-fd2b-ab97913c4a00"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-f1f8d65c146a>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m        \u001b[0;31m# Calculate training accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m        \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m        \u001b[0mtotal_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m        \u001b[0mcorrect_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BsNGp1S6VuRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and testing loss and accuracy graphs\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Loss plots\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, epoch + 2), train_losses, label='Training Loss')\n",
        "plt.plot(range(1, epoch + 2), [avg_test_loss] * (epoch + 1), label='Testing Loss')  # Repeat avg_test_loss for each epoch\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Testing Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Accuracy plots\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, epoch + 2), train_accuracies, label='Training Accuracy')\n",
        "plt.plot(range(1, epoch + 2), test_accuracies, label='Testing Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Testing Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a88DH-O6WO0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to randomly select and visualize an image from the test set\n",
        "def visualize_random_image():\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Select a random batch from the test loader\n",
        "        batch = next(iter(test_loader))\n",
        "        query_set, labels = batch\n",
        "        query_set, labels = query_set.to(device), labels.to(device)\n",
        "\n",
        "        # Make predictions\n",
        "        outputs = model(query_set)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Select a random image from the batch\n",
        "        index = np.random.choice(num_query * num_classes)\n",
        "        image = query_set[index].cpu().numpy().squeeze()\n",
        "        true_class = labels[index].item()\n",
        "        predicted_class = predicted[index].item()\n",
        "\n",
        "        # Visualize the image\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.title(f'True Class: {true_class}, Predicted Class: {predicted_class}')\n",
        "        plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "BcrJr8KUWO9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the function to visualize a random image\n",
        "visualize_random_image()"
      ],
      "metadata": {
        "id": "bu-U5seRWeJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6TMM-rVmXSDs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}